# Story 2.3: Wan2.5 Inference Container Dependencies
# PyTorch and CUDA dependencies for GPU inference

# Core ML frameworks
# Note: torch is installed separately with CUDA support in Dockerfile
torchvision>=0.15.0

# Diffusers with Wan pipeline support (requires latest for WanPipeline)
# Install from GitHub main branch for Wan2.1/2.2 support
diffusers>=0.32.0
transformers>=4.45.0
accelerate>=0.34.0
safetensors>=0.4.0
sentencepiece>=0.2.0

# FastAPI and server
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.5.0
python-multipart>=0.0.6

# AWS integration
boto3>=1.29.0
botocore>=1.32.0

# Image/Video processing
Pillow>=10.1.0
opencv-python-headless>=4.8.0
imageio>=2.31.0
imageio-ffmpeg>=0.4.9

# Utilities
numpy>=1.24.0
requests>=2.31.0
tqdm>=4.66.0

# Monitoring and logging
prometheus-client>=0.19.0
